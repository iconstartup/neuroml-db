{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas import DataFrame\n",
    "#import numpy as np\n",
    "#df = DataFrame.from_csv('pca_normed.csv')\n",
    "#np.unique(df['Multi_Spike_Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "feature_count = 39\n",
    "predict_column = -3\n",
    "\n",
    "#column_vector = [1] * feature_count\n",
    "#target_cluster = 1\n",
    "def train_model(column_vector = [1] * feature_count, target_cluster = 0):\n",
    "    plot = False\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    from pandas import DataFrame\n",
    "    import numpy as np\n",
    "    import pandas\n",
    "    from matplotlib import pyplot as plt\n",
    "    from sklearn.utils import class_weight\n",
    "\n",
    "    pandas.set_option('display.max_columns', None)\n",
    "    pandas.set_option('display.max_rows', 20)\n",
    "\n",
    "    np.random.seed(1412)\n",
    "    tf.set_random_seed(1412)\n",
    "\n",
    "    df = DataFrame.from_csv('pca_normed.csv')\n",
    "\n",
    "    # use just the selected columns + the label column\n",
    "    df = df[[x for x in np.where(np.array(column_vector) == 1)[0]]+[predict_column]]\n",
    "    \n",
    "    # remove nan labels\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Shuffle the rows\n",
    "    order = np.argsort(np.random.random(df.values[:,-1].shape))\n",
    "    df = df.values[order]\n",
    "\n",
    "    test_fraction = 0.2\n",
    "\n",
    "\n",
    "    cut_point = int(round(len(df)*test_fraction))\n",
    "    test_set = df[:cut_point]\n",
    "    train_set = df[cut_point:]\n",
    "\n",
    "    (train_rows, train_labels), (test_rows,test_labels) = (train_set[:,0:-1], train_set[:,-1]), (test_set[:,0:-1], test_set[:,-1]), \n",
    "    train_labels = np.where(train_labels != target_cluster,0,1)\n",
    "    test_labels = np.where(test_labels != target_cluster,0,1)\n",
    "\n",
    "    print(\"in train:\",len(np.where(train_labels == 1)[0]))\n",
    "    print(\"in test: \",len(np.where(test_labels == 1)[0]))\n",
    "\n",
    "    def match_targets(rows, labels):\n",
    "        target_i = np.where(labels == 1)\n",
    "        non_target_i = np.where(labels != 1)\n",
    "\n",
    "        #print('non target',len(non_target_i[0]),'target',len(target_i[0]))\n",
    "\n",
    "        if len(non_target_i[0]) >= len(target_i[0]):\n",
    "            non_target_rows = rows[non_target_i]\n",
    "            non_target_labels = labels[non_target_i]\n",
    "\n",
    "            matching_nt_i = np.random.choice(non_target_rows.shape[0], len(target_i[0]), replace=False)\n",
    "        else:\n",
    "            matching_nt_i = non_target_i\n",
    "\n",
    "            target_rows = rows[target_i]\n",
    "            target_labels = labels[target_i]\n",
    "\n",
    "            target_i = np.random.choice(target_rows.shape[0], len(non_target_i[0]), replace=False)\n",
    "\n",
    "        rows = np.concatenate((rows[matching_nt_i], rows[target_i]))\n",
    "        labels = np.concatenate((labels[matching_nt_i], labels[target_i]))\n",
    "\n",
    "        order = np.argsort(np.random.random(len(rows)))\n",
    "        rows = rows[order]\n",
    "        labels = labels[order]\n",
    "\n",
    "        return rows, labels\n",
    "\n",
    "    train_rows, train_labels = match_targets(train_rows, train_labels)\n",
    "    test_rows,  test_labels = match_targets(test_rows, test_labels)\n",
    "\n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "        if plot:\n",
    "            if epoch % 100 == 0: print('')\n",
    "            print('.', end='')    \n",
    "\n",
    "    def plot_history(histories, key='acc'): #binary_crossentropy\n",
    "      plt.figure(figsize=(16,10))\n",
    "\n",
    "      for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "                 label=name.title()+' Train')\n",
    "\n",
    "      plt.xlabel('Epochs')\n",
    "      plt.ylabel(key.replace('_',' ').title())\n",
    "      plt.legend()\n",
    "\n",
    "      plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "      print('train sample')\n",
    "      plt.figure(figsize=(16,5))\n",
    "      plt.plot(np.where(model.predict(train_rows) > 0.5, 1, 0))\n",
    "      plt.plot(train_labels)\n",
    "      #plt.xlim((0,150))\n",
    "\n",
    "      print('test sample')\n",
    "      plt.figure(figsize=(16,5))\n",
    "      plt.plot(np.where(model.predict(test_rows) > 0.5, 1, 0))\n",
    "      plt.plot(test_labels)\n",
    "      #plt.xlim((0,150))\n",
    "\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Dense(20, activation=keras.activations.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(7, activation=keras.activations.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(3, activation=keras.activations.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(1, activation=keras.activations.sigmoid)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=0.01, nesterov=True),\n",
    "                 loss='binary_crossentropy',\n",
    "                  metrics=['binary_accuracy', 'binary_crossentropy']\n",
    "    )\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(train_labels),\n",
    "                                                     train_labels)\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    print('starting training...')\n",
    "    history = model.fit(train_rows, \n",
    "              train_labels, \n",
    "              epochs=1000,\n",
    "              validation_data=(test_rows, test_labels),\n",
    "              callbacks=[early_stop, PrintDot()],\n",
    "              class_weight=class_weights,\n",
    "              verbose=0\n",
    "    )\n",
    "\n",
    "    print('training complete...')\n",
    "\n",
    "    if plot:\n",
    "        plot_history([('baseline', history)],key='binary_accuracy')\n",
    "\n",
    "    result = model.evaluate(test_rows, test_labels)[1]\n",
    "\n",
    "    print('best result', result, 'columns', sum(column_vector))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in train: 6\n",
      "in test:  4\n",
      "starting training...\n",
      "training complete...\n",
      "8/8 [==============================] - 0s 195us/step\n",
      "best result 1.0 columns 39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justas/anaconda2/envs/p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/justas/anaconda2/envs/p27/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of evolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justas/anaconda2/envs/p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in train: 46\n",
      "in test:  7\n",
      "starting training...\n",
      "training complete...\n",
      "14/14 [==============================] - 0s 81us/step\n",
      "best result 1.0 columns 16\n",
      "  Evaluated 1 individuals\n",
      "-- Generation 1 --\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-261745605472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# Select the next generation individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Clone the selected individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/justas/anaconda2/envs/p27/lib/python2.7/site-packages/deap/tools/selection.pyc\u001b[0m in \u001b[0;36mselTournament\u001b[0;34m(individuals, k, tournsize, fit_attr)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# the goal ('fitness') function to be maximized\n",
    "def evalOneMax(individual):\n",
    "    columns = sum(individual)\n",
    "    best_acc = train_model(individual)\n",
    "    \n",
    "    fit_cols = (feature_count - columns) / (1.0 * feature_count)\n",
    "    fit_acc = best_acc\n",
    "        \n",
    "    return fit_cols + fit_acc, # Note the ',' at the end\n",
    "\n",
    "pop_size = 100\n",
    "mate_top_percent = 0.20\n",
    "mutate_fraction = 0.05\n",
    "max_fitness = 2.0\n",
    "max_gens = 20\n",
    "\n",
    "pool_size = 15\n",
    "\n",
    "# CXPB  is the probability with which two individuals\n",
    "#       are crossed\n",
    "#\n",
    "# MUTPB is the probability for mutating an individual\n",
    "CXPB, MUTPB = 0.5, 0.2\n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from multiprocessing import Process, Pool\n",
    "import os\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "pool = Pool(pool_size, maxtasksperchild=1)\n",
    "\n",
    "if pool_size > 1:\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "else:\n",
    "    toolbox.register(\"map\", map)\n",
    "\n",
    "# Attribute generator \n",
    "#                      define 'attr_bool' to be an attribute ('gene')\n",
    "#                      which corresponds to integers sampled uniformly\n",
    "#                      from the range [0,1] (i.e. 0 or 1 with equal\n",
    "#                      probability)\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# Structure initializers\n",
    "#                         define 'individual' to be an individual\n",
    "#                         consisting of 100 'attr_bool' elements ('genes')\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, feature_count)\n",
    "\n",
    "# define the population to be a list of individuals\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "#----------\n",
    "# Operator registration\n",
    "#----------\n",
    "# register the goal / fitness function\n",
    "toolbox.register(\"evaluate\", evalOneMax)\n",
    "\n",
    "# register the crossover operator\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\n",
    "# register a mutation operator with a probability to\n",
    "# flip each attribute/gene of 0.05\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=mutate_fraction)\n",
    "\n",
    "# operator for selecting individuals for breeding the next\n",
    "# generation: each individual of the current generation\n",
    "# is replaced by the 'fittest' (best) of three individuals\n",
    "# drawn randomly from the current generation.\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=int(pop_size*mate_top_percent))\n",
    "\n",
    "random.seed(64)\n",
    "\n",
    "# create an initial population of 300 individuals (where\n",
    "# each individual is a list of integers)\n",
    "pop = toolbox.population(n=pop_size)\n",
    "\n",
    "print(\"Start of evolution\")\n",
    "\n",
    "# Evaluate the entire population\n",
    "fitnesses = list(pool.map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "print(\"  Evaluated %i individuals\" % len(pop))\n",
    "\n",
    "# Extracting all the fitnesses of \n",
    "fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "# Variable keeping track of the number of generations\n",
    "g = 0\n",
    "\n",
    "# Begin the evolution\n",
    "while max(fits) < max_fitness and g < max_gens:\n",
    "    # A new generation\n",
    "    g = g + 1\n",
    "    print(\"-- Generation %i --\" % g)\n",
    "\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "\n",
    "        # cross two individuals with probability CXPB\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "\n",
    "            # fitness values of the children\n",
    "            # must be recalculated later\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "\n",
    "        # mutate an individual with probability MUTPB\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = pool.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    print(\"  Evaluated %i individuals\" % len(invalid_ind))\n",
    "\n",
    "    # The population is entirely replaced by the offspring\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "    print(\"  Min %s\" % min(fits))\n",
    "    print(\"  Max %s\" % max(fits))\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "\n",
    "print(\"-- End of (successful) evolution --\")\n",
    "\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
